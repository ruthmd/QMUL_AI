{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kT2CO3WQ_uZc"
   },
   "source": [
    "# Neural networks for Classification - FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12787,
     "status": "ok",
     "timestamp": 1701076865685,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "3ukiRwCrB-A9",
    "outputId": "167cf305-c7ca-419e-fdfd-b623b6414a0d"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(root = \".\", train=True,\n",
    "download=True, transform=transforms.ToTensor())\n",
    "test_set = torchvision.datasets.FashionMNIST(root = \".\", train=False,\n",
    "download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "# fix the seed to be able to get the same randomness across runs and hence reproducible outcomes\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "# if you are using CuDNN , otherwise you can just ignore\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1701076866449,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "lZ7ggePbDLdK",
    "outputId": "662ef78a-95f5-4a37-c339-28df2547e8f2"
   },
   "outputs": [],
   "source": [
    "input_data, label = next(iter(train_loader))\n",
    "plt.imshow(input_data[0,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\");\n",
    "print(\"Label is: {}\".format(label[0]))\n",
    "print(\"Dimension of input data: {}\".format(input_data.size()))\n",
    "print(\"Dimension of labels: {}\".format(label.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701076866449,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "HYWt40a3DWg4"
   },
   "outputs": [],
   "source": [
    "# From Lab 06_3\n",
    "# CNN implementation\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyCNN, self).__init__()\n",
    "\n",
    "    # Parameters to input to nn.Conv2d as specified in the task\n",
    "    # 1: number of input channels (1 for the images of the FashionMNIST dataset)\n",
    "    # 2: number of output channels\n",
    "    # 3: kernel dimensionality (1 dimension if both dimensions are the same)\n",
    "    # 4: stride dimensionality (1 dimension if both dimensions are the same)\n",
    "\n",
    "    # self.conv = nn.Conv2d(1, 12, kernel_size=3, stride=1)\n",
    "\n",
    "    # activation function as specified in the task\n",
    "    # self.act_conv = nn.ELU()\n",
    "\n",
    "    # Parameters to input to nn.MaxPool2d as specified in the task\n",
    "    # 1: kernel dimensionality (1 dimension if both dimensions are the same)\n",
    "    # 2: stride dimensionality (1 dimension if both dimensions are the same)\n",
    "\n",
    "    # self.max_pool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "    # Parameters to input to nn.Conv2d\n",
    "    # 1: the first input parameter specifies the number of output channels from the previous layer (i.e. 12)\n",
    "\n",
    "    # self.conv1 = nn.Conv2d(12, 26, kernel_size=3, stride=1)\n",
    "    # self.act_conv1 = nn.ELU()\n",
    "    # self.max_pool1 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "\n",
    "    # alternatively use the Sequential container to run layers sequentially\n",
    "    self.cnn_model = nn.Sequential(nn.Conv2d(1, 12, kernel_size = 3, stride=1), nn.ELU(), nn.MaxPool2d(2, stride=2), nn.Conv2d(12, 26, kernel_size = 3, stride = 1), nn.ELU(), nn.MaxPool2d(2, stride = 2))\n",
    "\n",
    "\n",
    "    # Parameters to input to nn.Linear\n",
    "    # 1: last output dimension of the previous layer\n",
    "    # Note: if previous layer is a CNN or a MaxPool layer the dimension is the one of the flattened output\n",
    "    # Note: we keep the batch_size dimension constant in the network\n",
    "    # for example, 32 x 5 x 5 x 26 (batch_size x (5 x 5 x 26) feature matrix) -> 32 x 650 (5*5*26)\n",
    "    # 2: output dimension\n",
    "\n",
    "    # self.fc = nn.Linear(650, 650)\n",
    "    # self.act = nn.ELU()\n",
    "\n",
    "    # dropout is applied after the activation\n",
    "    # self.drop = nn.Dropout(0.5)\n",
    "\n",
    "    # self.fc1 = nn.Linear(650, 256)\n",
    "    # self.act1 = nn.ELU()\n",
    "    # self.drop1 = nn.Dropout(0.5)\n",
    "\n",
    "    # self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    # alternatively use the Sequential container to run layers sequentially\n",
    "    self.fc_model = nn.Sequential(nn.Linear(650, 650), nn.ELU(), nn.Dropout(0.5), nn.Linear(650,256), nn.ELU(), nn.Dropout(0.5), nn.Linear(256, 10))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # pass input via the CNN layers\n",
    "    x = self.cnn_model(x)\n",
    "    # we reshape the tensor\n",
    "    # we keep the first dimension (batch_size)\n",
    "    # we let Pytorch compute the second dimension\n",
    "    # (-1 means compute this dimension given the others)\n",
    "    x =x.view(x.size(0), -1)\n",
    "    # pass input via the fully-connected layers\n",
    "    x = self.fc_model(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701076866449,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "heoTif1ZmAR9"
   },
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "  total, correct = 0,0\n",
    "  # turn on evaluate mode, this de-activates certain modes such as dropout\n",
    "  # good practice to include in your projects\n",
    "  net.eval()\n",
    "  for data in dataloader:\n",
    "\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    # we take the index of the class that received the highest value\n",
    "    # we take outputs.data so that no backpropagation is performed for these outputs\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    # .item() takes Python float values from the tensor\n",
    "    correct += (pred == labels).sum().item()\n",
    "  return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701076866449,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "v5ouHAGgmAR9"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    # initialise both linear and convolutional layers\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620811,
     "status": "ok",
     "timestamp": 1701077487257,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "p-sMuBAtmAR-",
    "outputId": "16248291-c484-423d-eb58-f158a3cbb9ac"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "net = MyCNN().to(device)\n",
    "# initialise weights\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Note: CrossEntropy loss is usually used for classification tasks\n",
    "# check slide 23 of Lecture 8.2\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "\n",
    "# SGD optimiser, learning rate is specified by alpha\n",
    "opt = torch.optim.SGD(list(net.parameters()), lr=alpha)\n",
    "\n",
    "loss_epoch_array = []\n",
    "max_epochs = 30\n",
    "loss_epoch = 0\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "# loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "  # we will compute sum of batch losses per epoch\n",
    "  loss_epoch = 0\n",
    "  # loop over batches\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    # to ensure the training mode is \"turned on\"\n",
    "    net.train()\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # zero the gradients\n",
    "    opt.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    # compute the loss\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    # calculate the gradients\n",
    "    loss.backward()\n",
    "    # update the parameters using the gradients and optimizer algorithm\n",
    "    opt.step()\n",
    "    # we sum the loss over batches\n",
    "    loss_epoch += loss.item()\n",
    "\n",
    "  loss_epoch_array.append(loss_epoch)\n",
    "  train_accuracy.append(evaluation(train_loader))\n",
    "  test_accuracy.append(evaluation(test_loader))\n",
    "  print(\"Epoch {}: loss: {}, train accuracy: {}, valid accuracy:{}\".format(epoch + 1, loss_epoch_array[-1], train_accuracy[-1], test_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1701077487725,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "9kodu9LzmAR-",
    "outputId": "2c8715b4-f6e9-4e36-9184-5302054f8b1d"
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(train_accuracy, \"r\")\n",
    "plt.plot(test_accuracy, \"b\")\n",
    "plt.gca().legend(('train','test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1701077487726,
     "user": {
      "displayName": "zahraa alsahili",
      "userId": "16817514495224653331"
     },
     "user_tz": 0
    },
    "id": "ip2S6ROWmAR_",
    "outputId": "e3480674-7f38-4cc7-cd3f-a141f49565a1"
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_epoch_array)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
