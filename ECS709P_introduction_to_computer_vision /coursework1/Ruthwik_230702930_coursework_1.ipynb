{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea6f48-0c4b-4296-be96-dc331dae796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sin,cos\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sin, cos\n",
    "\n",
    "def ICV_rotate(deg=None):\n",
    "    # Function to generate a rotation matrix given an angle in degrees\n",
    "    if deg is None:\n",
    "        rad = np.radians(int(input(\"Enter rotation angle in degrees (+/-):\")))\n",
    "    else:\n",
    "        rad = np.radians(deg)\n",
    "    rotation_matrix = np.array([[cos(rad), -sin(rad)], [sin(rad), cos(rad)]])\n",
    "    return rotation_matrix\n",
    "\n",
    "def ICV_skew(deg=None):\n",
    "    # Function to generate a skew matrix given an angle in degrees\n",
    "    if deg is None:\n",
    "        rad = np.radians(int(input(\"Enter skewing angle in degrees (+/-):\")))\n",
    "    else:\n",
    "        rad = np.radians(deg)\n",
    "    skew_matrix = np.array([[1, 0], [1 / np.tan(rad), 1]])\n",
    "    return skew_matrix\n",
    "\n",
    "def create_canvas(h, w, c, transform_matrix, offset):\n",
    "    # Function to create a canvas based on the transformation matrix and offset\n",
    "    corner_points = [\n",
    "        [0 - offset[1], 0 - offset[1], h - offset[1], h - offset[1]],\n",
    "        [0 - offset[0], w - offset[0], w - offset[0], 0 - offset[0]]\n",
    "    ]\n",
    "\n",
    "    # Apply the transformation matrix to corner points\n",
    "    transformed_corners = np.matmul(transform_matrix, corner_points)\n",
    "\n",
    "    # Calculate the dimensions of the canvas based on the transformed corner points\n",
    "    max_y, max_x = np.max(np.abs(transformed_corners), axis=1)\n",
    "    min_y, min_x = np.min(transformed_corners, axis=1)\n",
    "\n",
    "    max_x, max_y = int(2 * max_x), int(2 * max_y)\n",
    "    canvas = np.zeros((max_y, max_x, c), np.int32)\n",
    "\n",
    "    return canvas, (max_x, max_y), (min_x, min_y)\n",
    "\n",
    "def ICV_transform(img, transform_matrices):\n",
    "    h, w, c = img.shape\n",
    "    offset = (w // 2, h // 2)\n",
    "\n",
    "    # Create a transform_matrix from the dot product of transformation matrices\n",
    "    transform_matrix = np.dot(*transform_matrices) if len(transform_matrices) > 1 else transform_matrices[0]\n",
    "\n",
    "    # Generate a new canvas with offset points as origin\n",
    "    new_canvas, (max_x, max_y), (min_x, min_y) = create_canvas(h, w, c, transform_matrix, offset)\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # Apply the inverse transformation to map the pixel back to the original position\n",
    "            new_i, new_j = np.matmul(transform_matrix, [[i - offset[1]], [j - offset[0]]])\n",
    "\n",
    "            # Adjust coordinates based on minimum values (handling negative values)\n",
    "            if min_y < 0:\n",
    "                new_i += abs(min_y)\n",
    "            if min_x < 0:\n",
    "                new_j += abs(min_x)\n",
    "\n",
    "            # Check if the transformed pixel is within the canvas boundaries\n",
    "            if 0 <= new_i < max_y and 0 <= new_j < max_x:\n",
    "                new_canvas[int(new_i), int(new_j)] = img[i, j]\n",
    "\n",
    "    return new_canvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "font_properties = {\n",
    "    'family': 'sans-serif',\n",
    "    'size': 72,\n",
    "}\n",
    "\n",
    "ax.text(0.5, 0.5, \"RUTHWIK\", **font_properties, ha='center', va='center')\n",
    "plt.axis('off')\n",
    "plt.savefig('ruthwik.jpg') \n",
    "plt.title(\"Original image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ruthwik.jpg'\n",
    "img_bgr = cv2.imread(path, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_rotate(30)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_rotate(60)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_rotate(120)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_rotate(-50)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_skew(10)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_skew(40)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_skew(60)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_rotate(-20), ICV_skew(50)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ICV_transform(img_bgr, [ICV_skew(50), ICV_rotate(-20)])\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02947a",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_convolution(input_image, kernel):\n",
    "    \n",
    "    image_height, image_width = input_image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # Define the output image with the same size as the input image\n",
    "    output = np.zeros_like(input_image)\n",
    "\n",
    "    # Padding the input image to handle borders\n",
    "    pad_height = kernel_height // 2\n",
    "    pad_width = kernel_width // 2\n",
    "    \n",
    "    padded_image = np.pad(\n",
    "        input_image, \n",
    "        ((pad_height, pad_height), (pad_width, pad_width)),\n",
    "        mode='constant'\n",
    "    )\n",
    "\n",
    "    # Perform the convolution operation\n",
    "    for i in range(image_height):\n",
    "        for j in range(image_width):\n",
    "            # Extract the region of interest\n",
    "            region = padded_image[i:i + kernel_height, j:j + kernel_width]\n",
    "            # Apply the kernel (element-wise multiplication followed by sum)\n",
    "            output[i, j] = np.sum(region*kernel)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image\n",
    "image = cv2.imread('./Dataset/DatasetA/car-1.jpg', 0)\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "horizontal_edges = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "\n",
    "vertical_edges = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
    "\n",
    "kernel_a = (1/16)*np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "\n",
    "kernel_b = np.array([[0,1,0],[1,-4,1],[0,1,0]])\n",
    "\n",
    "kernel_avg = np.ones((3, 3)) / 9.0\n",
    "\n",
    "gaussian_kernel = (1/256)*np.array([\n",
    "    [1 , 4  ,  6 ,  4 , 1 ],\n",
    "    [4 , 16 , 24 , 16 , 4 ],\n",
    "    [6 , 24 , 36 , 24 , 6 ],\n",
    "    [4 , 16 , 24 , 16 , 4 ],\n",
    "    [1 , 4  ,  6 ,  4 , 1 ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_avg)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_a)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_b)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) A followed by A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_a)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ICV_convolution(result, kernel_a)\n",
    "plt.imshow(result2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) A followed by B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_a)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ICV_convolution(result, kernel_b)\n",
    "plt.imshow(result2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) B followed by A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ICV_convolution(image, kernel_b)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ICV_convolution(result, kernel_a)\n",
    "plt.imshow(result2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0e49d",
   "metadata": {},
   "source": [
    "## Video Segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Dataset/DatasetB.avi')\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 0\n",
    "seconds = 11\n",
    "n_frames = int(fps*(minutes*60 + seconds))\n",
    "print(n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(15):\n",
    "\n",
    "    ret, frame = video.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # plt.imshow(frame)\n",
    "    # plt.show()\n",
    "    \n",
    "    # frequency counts of pixel intensities\n",
    "    frequency_color = {\n",
    "        \"red\":  Counter(frame[:, :, 0].flatten()),\n",
    "        \"green\": Counter(frame[:, :, 1].flatten()),\n",
    "        \"blue\": Counter(frame[:, :, 2].flatten())\n",
    "    }\n",
    "\n",
    "    X = list(range(255))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for k, v in frequency_color.items():\n",
    "        ax.plot(X, [v[i] for i in X], label = k, color = k)\n",
    "    \n",
    "    # fig.savefig(f'./Dataset/DatasetB_hist_plots/color_hist_graph_{_}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0eeea",
   "metadata": {},
   "source": [
    "# 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_intersection(hist1, hist2):\n",
    "    # Ensure the histograms have the same length\n",
    "    assert len(hist1) == len(hist2), \"Histograms must have the same length\"\n",
    "\n",
    "    # Calculate the histogram intersection\n",
    "    intersection = np.sum(np.minimum(hist1, hist2))\n",
    "\n",
    "    return intersection\n",
    "\n",
    "def normalize_histogram(hist):\n",
    "    # Normalize the histogram to have a sum of 1\n",
    "    return hist/ np.sum(hist)\n",
    "\n",
    "def calculate_frame_intersections(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_hist = np.histogram(prev_frame_gray.flatten(), bins=256, range=[0, 256])[0]\n",
    "\n",
    "    # Lists to store intersection values and normalized intersection values\n",
    "    intersections = []\n",
    "    normalized_intersections = []\n",
    "\n",
    "    while True:\n",
    "        ret, curr_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        curr_frame_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_hist = np.histogram(curr_frame_gray.flatten(), bins=256, range=[0, 256])[0]\n",
    "\n",
    "        # Calculate histogram intersection\n",
    "        intersection_value = histogram_intersection(prev_hist, curr_hist)\n",
    "        intersections.append(intersection_value)\n",
    "\n",
    "        normalized_prev_hist = normalize_histogram(prev_hist)\n",
    "        normalized_curr_hist = normalize_histogram(curr_hist)\n",
    "        \n",
    "        # Calculate normalised histogram intersection\n",
    "        normalized_intersection = histogram_intersection(normalized_prev_hist, normalized_curr_hist)\n",
    "        normalized_intersections.append(normalized_intersection)\n",
    "\n",
    "        # Update previous histogram\n",
    "        prev_hist = curr_hist\n",
    "\n",
    "    cap.release()\n",
    "    return intersections, normalized_intersections\n",
    "\n",
    "def plot_intersections(intersections, normalized_intersections):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(intersections, label='Intersection Values')\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Intersection Value')\n",
    "    plt.title('Histogram Intersection Over Time')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(normalized_intersections, label='Normalized Intersection Values')\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Normalized Intersection Value')\n",
    "    plt.title('Normalized Histogram Intersection Over Time')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "video_path = './Dataset/DatasetB.avi'  # Replace with the actual video path\n",
    "intersections, normalized_intersections = calculate_frame_intersections(video_path)\n",
    "# print(intersections, normalized_intersections)\n",
    "plot_intersections(intersections, normalized_intersections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d7e32",
   "metadata": {},
   "source": [
    "# Texture Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_get_lbp_pixel(img, center, x, y): \n",
    "    new_value = 0\n",
    "    try: \n",
    "        if img[x][y] >= center: \n",
    "            new_value = 1\n",
    "    except IndexError: \n",
    "        pass\n",
    "    return new_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_lbp_calculated_pixel(img, x, y): \n",
    "    center = img[x][y] \n",
    "    bin_arr = [] \n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x-1, y-1))  # top_left \n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x-1, y))    # top\n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x-1, y + 1))  # top_right\n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x, y + 1))    # right \n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x + 1, y + 1))  # bottom_right\n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x + 1, y))    # bottom\n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x + 1, y-1))   # bottom_left\n",
    "    bin_arr.append(ICV_get_lbp_pixel(img, center, x, y-1))       # left\n",
    "    return int(''.join(map(str, bin_arr)), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_window(window):\n",
    "    height, width = window.shape\n",
    "    lbp_window = np.zeros((height, width), np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            lbp_window[i, j] = ICV_lbp_calculated_pixel(window, i, j)\n",
    "\n",
    "    # plot the LBP for given image window\n",
    "    plt.imshow(lbp_window, cmap =\"gray\") \n",
    "    plt.show() \n",
    "    \n",
    "    x = list(range(256))\n",
    "    y = np.array([Counter(lbp_window.flatten())[i] for i in x])\n",
    "    plt.bar(x, y/np.max(y)) \n",
    "    plt.show()\n",
    "    return lbp_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_get_lbp_img(img, window_size):\n",
    "    height, width = img.shape\n",
    "    # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_lbp = np.zeros((height, width), np.uint8)\n",
    "\n",
    "    for i in range(0, height, window_size):\n",
    "        for j in range(0, width, window_size):\n",
    "            window = img[i:i+window_size, j:j+window_size]\n",
    "            \n",
    "            # plot the window of the image \n",
    "            plt.imshow(window, cmap =\"gray\") \n",
    "            plt.show() \n",
    "\n",
    "            lbp_window = compute_lbp_window(window)\n",
    "            img_lbp[i:i+window_size, j:j+window_size] = lbp_window\n",
    "\n",
    "   \n",
    "    return img_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./Dataset/DatasetA/face-3.jpg', 0)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./Dataset/DatasetA/face-3.jpg', 0)\n",
    "window_size = 64\n",
    "\n",
    "img_lbp = ICV_get_lbp_img(image, window_size)\n",
    "\n",
    "# Print the shape of the img_lbp array\n",
    "print(\"Shape of img_lbp:\", img_lbp.shape)\n",
    "\n",
    "# Ensure img_lbp values are within the valid range (0 to 255)\n",
    "img_lbp = np.clip(img_lbp, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Display the LBP image\n",
    "plt.imshow(img_lbp, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1993c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_lbp_classify(img, window_size):\n",
    "    # Function to perform Local Binary Pattern (LBP) classification on an image\n",
    "    img_height, img_width = img.shape\n",
    "    hw = window_size // 2  # Half of the window size for boundary handling\n",
    "    bins = 255  # Number of bins for the LBP histogram\n",
    "    features = []  # List to store LBP histograms for each window\n",
    "    des = np.zeros(img.shape)\n",
    "\n",
    "    # Iterate over image windows\n",
    "    for y in range(hw, img_height - hw, window_size):\n",
    "        for x in range(hw, img_width - hw, window_size):\n",
    "\n",
    "            # Extract the window from the image\n",
    "            window = img[y - hw:y + hw, x - hw:x + hw]\n",
    "            lbp = np.zeros(window.shape)\n",
    "\n",
    "            # Compute LBP for each pixel in the window\n",
    "            for i in range(1, window.shape[0] - 1):\n",
    "                for j in range(1, window.shape[1] - 1):\n",
    "\n",
    "                    center = window[i, j]\n",
    "                    code = 0\n",
    "\n",
    "                    # Compare the pixel values with the center pixel for LBP encoding\n",
    "                    if window[i - 1, j - 1] > center: code |= 1\n",
    "                    if window[i - 1, j] > center: code |= 2\n",
    "                    if window[i - 1, j + 1] > center: code |= 4\n",
    "                    if window[i, j + 1] > center: code |= 8\n",
    "                    if window[i + 1, j + 1] > center: code |= 16\n",
    "                    if window[i + 1, j] > center: code |= 32\n",
    "                    if window[i + 1, j - 1] > center: code |= 64\n",
    "                    if window[i, j - 1] > center: code |= 128\n",
    "                    lbp[i, j] = code\n",
    "\n",
    "            des[x:x+window_size, y:y+window_size] = lbp\n",
    "\n",
    "            # Build LBP histogram for the window\n",
    "            hist, _ = np.histogram(lbp, bins=bins, range=(0, 255))\n",
    "           \n",
    "            # Normalize the histogram\n",
    "            hist = hist / np.max(hist)\n",
    "            features.append(hist)\n",
    "\n",
    "            # des[x, y] = lbp\n",
    "            \n",
    "\n",
    "    # plt.imshow(des, cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "    # Sum of normalized histograms as the final feature\n",
    "    normalised_sum = np.sum(features)\n",
    "    return normalised_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "\n",
    "car1 = cv2.imread('./Dataset/DatasetA/car-1.jpg',0)\n",
    "# plt.imshow(car1, cmap='gray')\n",
    "car2 = cv2.imread('./Dataset/DatasetA/car-2.jpg',0)\n",
    "car3 = cv2.imread('./Dataset/DatasetA/car-1.jpg',0)\n",
    "\n",
    "face1 = cv2.imread('./Dataset/DatasetA/face-1.jpg',0)\n",
    "# plt.imshow(face1, cmap='gray')\n",
    "face2 = cv2.imread('./Dataset/DatasetA/face-1.jpg',0)\n",
    "face3 = cv2.imread('./Dataset/DatasetA/face-1.jpg',0)\n",
    "\n",
    "\n",
    "car1_des_val= ICV_lbp_classify(car1, window_size)\n",
    "car2_des_val = ICV_lbp_classify(car2, window_size)\n",
    "car3_des_val = ICV_lbp_classify(car3, window_size)\n",
    "\n",
    "face1_des_val= ICV_lbp_classify(face1, window_size)\n",
    "face2_des_val = ICV_lbp_classify(face2, window_size)\n",
    "face3_des_val = ICV_lbp_classify(face3, window_size)\n",
    "\n",
    "\n",
    "\n",
    "print(\"car\", car1_des_val, car2_des_val, car3_des_val)\n",
    "print(\"face\", face1_des_val, face2_des_val, face3_des_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate methods: contouring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_frame_difference(video):\n",
    "\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    differences=[]\n",
    "    minutes = 0\n",
    "    seconds = 5\n",
    "    frame_id = int(fps*(minutes*60 + seconds))\n",
    "\n",
    "    #Calculate the first frame as reference frame\n",
    "    _, frame = video.read()\n",
    "    referenceFrame = frame\n",
    "    referenceFrame = cv2.cvtColor(referenceFrame, cv2.COLOR_BGR2GRAY)\n",
    "    referenceFrame = referenceFrame.astype(int)\n",
    "\n",
    "\n",
    "    for x in range(frame_id):\n",
    "        _, frame = video.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"Selected frame\")\n",
    "\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "        plt.show()\n",
    "        frame = frame.astype(int)\n",
    "        # Compute the absolute difference between referenceFrame and frame\n",
    "        difference = np.abs(referenceFrame - frame)\n",
    "        print(\"difference\")\n",
    "\n",
    "        plt.imshow(difference, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        difference = np.where(difference > 40, 0, 255)\n",
    "        differences.append(difference)\n",
    "        \n",
    "        print(\"threshold difference\")\n",
    "        plt.imshow(difference, cmap='gray')\n",
    "        plt.show()\n",
    "        # plt.savefig('Frame Difference By First frame '+str(x + 1)+'.jpg')\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Dataset/DatasetC.avi')\n",
    "ICV_frame_difference(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_frame_difference_conseq_frame(video):\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    differences=[]\n",
    "    minutes = 0\n",
    "    seconds = 5\n",
    "    frame_id = int(fps*(minutes*60 + seconds))\n",
    "\n",
    "    # first frame as reference frame\n",
    "    _, frame = video.read()\n",
    "    referenceFrame = frame\n",
    "    referenceFrame = cv2.cvtColor(referenceFrame, cv2.COLOR_BGR2GRAY)\n",
    "    referenceFrame = referenceFrame.astype(int)\n",
    "\n",
    "\n",
    "    for x in range(frame_id):\n",
    "        print(f\"frame_id: {x}\")\n",
    "        _, frame = video.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"Selected frame\")\n",
    "\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "        plt.show()\n",
    "        frame = frame.astype(int)\n",
    "    \n",
    "        # Compute the absolute difference between referenceFrame and frame\n",
    "        difference = np.abs(referenceFrame - frame)\n",
    "        print(\"difference\")\n",
    "        plt.imshow(difference, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        difference = np.where(difference > 40, 0,255)\n",
    "        differences.append(difference)\n",
    "        referenceFrame = frame\n",
    "        # plt.figure()\n",
    "        print(\"threshold difference\")\n",
    "        plt.imshow(difference, cmap='gray')\n",
    "        plt.show()\n",
    "        # plt.savefig('Frame Difference By previous frame '+str(x + 1)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Dataset/DatasetC.avi')\n",
    "ICV_frame_difference_conseq_frame(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_generate_background(vid):\n",
    "    it,frame = vid.read()\n",
    "    \n",
    "    # get the first frame\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    AllFrames = np.zeros(frame.shape, dtype='uint8')\n",
    "    frameNUmber=1\n",
    "\n",
    "    while(vid.isOpened()):\n",
    "        # Reading the frames of video\n",
    "        it, frame = vid.read()\n",
    "        if not it:\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # linearly increasing weights based on frame numbers\n",
    "        AllFrames = (AllFrames*(frameNUmber-1)+frame)/frameNUmber\n",
    "        AllFrames.astype(int)\n",
    "        frameNUmber += 1\n",
    "        \n",
    "    pil_img=Image.fromarray((AllFrames).astype(np.uint8)) \n",
    "    plt.imshow(pil_img,cmap='gray')\n",
    "    pil_img.save('Background.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Dataset/DatasetC.avi')\n",
    "ICV_generate_background(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_object_counter(global_backgroud_image, video):\n",
    "    object_counts = []\n",
    "\n",
    "    for x in range(125):\n",
    "        _, frame = video.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "        # Compute the absolute difference between referenceFrame and frame\n",
    "        difference = np.abs(global_backgroud_image - frame)\n",
    "\n",
    "        # set manual threshold for difference\n",
    "        difference = np.where(difference > 100, 255, 0)\n",
    "        object_count = np.count_nonzero(difference) // 8000\n",
    "        \n",
    "        object_counts.append(object_count)\n",
    "    \n",
    "    return object_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('./Dataset/DatasetC.avi')\n",
    "global_backgroud_image = cv2.imread(\"Background.jpg\",0)\n",
    "objects_count = ICV_object_counter(global_backgroud_image,video)\n",
    "print(objects_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(125)), objects_count)\n",
    "plt.xlabel('Video frame')\n",
    "plt.ylabel('objects')\n",
    "plt.title('Ojects per frame')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
