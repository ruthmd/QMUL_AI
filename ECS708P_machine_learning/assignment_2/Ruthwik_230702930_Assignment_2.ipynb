{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpte-at4T79w"
      },
      "source": [
        "## 0. Introduction\n",
        "\n",
        "The aim of this lab is to get familiar with **Mixture of Gaussians** model.\n",
        "\n",
        "\n",
        "1.   This lab is the course-work activity **Assignment 2: Unsupervised Learning(20%)**\n",
        "2. The Assignment is due on **Friday , 8th December, 11:59pm**\n",
        "2.   A report answering the <font color = 'red'>**questions in</font><font color = \"maroon\"> red**</font> should be submitted on QMplus along with the completed Notebook.\n",
        "3. The report should be a separate file in **pdf format** (so **NOT** *doc, docx, notebook* etc.), well identified with your name, student number, assignment number (for instance, Assignment 1), module code.\n",
        "4. Make sure that **any figures or code** you comment on, are **included in the report**.\n",
        "5. No other means of submission other than the appropriate QM+ link is acceptable at any time (so NO email attachments, etc.)\n",
        "6. **PLAGIARISM** <ins>is an irreversible non-negotiable failure in the course</ins> (if in doubt of what constitutes plagiarism, ask!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz2sG0zXUIJ9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "%matplotlib inline\n",
        "plt.rcParams['font.size'] = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GspA1XVXUIm0"
      },
      "source": [
        "For this lab, we will use the Peterson and Barney’s dataset of vowel formant frequencies. (For more info, look at Classification of Peterson & Barney’s vowels using Weka. - a copy of this article is on QMplus)\n",
        "\n",
        "More specifically, Peterson and Barney measured the fundamental frequency $F0$ and the first three formant frequencies ($F1-F3$) of sustained English Vowels, using samples from various speakers.\n",
        "\n",
        "Upload the .npy file and load it using the code block below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vt8VuacxJQ-"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.upload()\n",
        "data_npy_file = 'PB_data.npy'\n",
        "\n",
        "# Loading data from .npy file\n",
        "data = np.load(data_npy_file, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dseq4YO7U-X0"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhkgMnfVJJf"
      },
      "source": [
        "The dataset contains 4 vectors ($F0-F3$), containing the fundamental frequencies ($F0$, $F1$, $F2$ and $F3$) for each phoneme and another vector “phoneme\\_id” containing a number representing the id of the phoneme.\n",
        "\n",
        "In the exercises that follow, we will use only the dataset associated with formants $F1$ and $F2$.\n",
        "\n",
        "**Note**: Phonemes and Frequencies are two different things; phoneme_id is the ground truth class of each row while frequencies represent features of each data point. Please review the papers provided with the lab materials for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPmOjeP5ViH1"
      },
      "outputs": [],
      "source": [
        "data = np.ndarray.tolist(data)\n",
        "# Array that contains the phoneme ID (1-10) of each sample\n",
        "phoneme_id = data['phoneme_id']\n",
        "\n",
        "# frequencies f1 and f2\n",
        "f1 = data['f1']\n",
        "f2 = data['f2']\n",
        "\n",
        "print(np.unique(phoneme_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68cJhaVP1G4l"
      },
      "source": [
        "### <font color=\"red\"> Q1. Produce a plot of F1 against F2. (You should be able to spot some clusters already in this scatter plot). Comment on the figure and the visible clusters [2 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots()\n",
        "uniq=np.unique(phoneme_id)\n",
        "\n",
        "ax.set_xlabel('F1 Frequency')\n",
        "ax.set_ylabel('F2 Frequency')\n",
        "ax.set_title('F1 vs. F2')\n",
        "ax.grid(True)\n",
        "\n",
        "for i in uniq:\n",
        "     ax.scatter(f1[phoneme_id==i], f2[phoneme_id==i],marker='.', label=f\"phoneme {i}\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUabt7iEWLkn"
      },
      "outputs": [],
      "source": [
        "### your code here\n",
        "plt.scatter(f1, f2, c=phoneme_id, s=4, alpha=0.8)\n",
        "plt.title('F1 vs. F2')\n",
        "plt.xlabel('F1 Frequency')\n",
        "plt.ylabel('F2 Frequency')\n",
        "plt.colorbar(label='Phoneme ID')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dz_5r1KI4mp"
      },
      "source": [
        "# 1. MoG Using the EM algorithm\n",
        "\n",
        "Recall the following definition of a Mixture of Gaussians. Assuming our observed random vector is $\\mathbf{x}\\in\\mathbb{R}^D$, a MoG models $p(\\mathbf{x})$ as a sum of $K$-many weighted Gaussians. More specifically:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        " p(\\mathbf{x}) = \\sum_{k=1}^K \\frac{p(c_{k})}{(2\\pi)^{D/2} \\mathrm{det}\\left(\\boldsymbol\\Sigma_k\\right)^{1/2}}\n",
        " % \\exp(-\\frac{1}{2}(x-\\mu)^T \\sum_{k}^{-1}(x-\\mu))\n",
        " \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol\\mu_k)^\\top {\\boldsymbol\\Sigma_k}^{-1}(\\mathbf{x}-\\boldsymbol\\mu_k)\\right),\n",
        "\\end{equation}\n",
        "where:\n",
        "* $\\boldsymbol\\mu_k\\in\\mathbb{R}^{D}$\n",
        "* $\\boldsymbol\\Sigma_{k}\\in\\mathbb{R}^{D\\times D}$\n",
        "* $p(c_{k})=\\pi_k\\in\\mathbb{R}$\n",
        "\n",
        "denote the $k$-th gaussian component's **mean vector**, **covariance matrix**, and **mixture coefficients** respectively. The $K$-many gaussian components' model parameters are referred to collectively as $\\theta = \\{\\boldsymbol\\mu_k,\\boldsymbol\\Sigma_{k},\\pi_k\\}_{k=1}^K$.\n",
        "\n",
        "## EM Algorithm\n",
        "For the E step we softly assign each datum to the closest centroid (using the current iteration's fixed model parameters) as in the K means example.\n",
        "\n",
        "For the M step we update the model parameters $\\theta$ to maximize the weighted log-likelihood.\n",
        "At a high level, for each centroid k we:\n",
        "* Update the mean vectors\n",
        "* Update the covariance matrices (We will fit Gaussians with diagonal covariance matrices)\n",
        "* Set the mixture coefficients as the mean probability of a sample being generated by the k-th gaussian component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS1ea5HoWNTL"
      },
      "source": [
        "Read the code below and understand what it is calculating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vNV5ji1WhZJ"
      },
      "outputs": [],
      "source": [
        "def get_predictions(mu, s, p, X):\n",
        "\t\"\"\"\n",
        "\t\t:param mu\t\t\t: means of GMM components\n",
        "\t\t:param s\t\t\t: covariances of GMM components\n",
        "\t\t:param p \t\t\t: weights of GMM components\n",
        "\t\t:param X\t\t\t: 2D array of our dataset\n",
        "\t\"\"\"\n",
        "\n",
        "\t# get number of GMM components\n",
        "\tk = s.shape[0]\n",
        "\t# get number of data samples\n",
        "\tN = X.shape[0]\n",
        "\t# get dimensionality of our dataset\n",
        "\tD = X.shape[1]\n",
        "\n",
        "\tZ = np.zeros((N, k))\n",
        "\tfor i in range(k):\n",
        "\t\tmu_i = mu[i, :]\n",
        "\t\tmu_i = np.expand_dims(mu_i, axis=1)\n",
        "\t\tmu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\t\tX_minus_mu = X - mu_i_repeated.transpose()\n",
        "\t\tinverse_s = scipy.linalg.pinv(s[i])\n",
        "\t\tinverse_s = np.squeeze(inverse_s)\n",
        "\t\ts_i_det = scipy.linalg.det(s[i])\n",
        "\t\tx_s_x = np.matmul(X_minus_mu, inverse_s)*X_minus_mu\n",
        "\t\tZ[:, i] = p[i]*(1/np.power(((2*np.pi)**D) * np.abs(s_i_det), 0.5)) * np.exp(-0.5*np.sum(x_s_x, axis=1))\n",
        "\treturn Z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PebY0ALYbI7"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfM20ivYYe4B"
      },
      "outputs": [],
      "source": [
        "def plot_gaussians(ax, s, mu, X, title_string):\n",
        "    \"\"\"\n",
        "        :param X            : 2D array of our dataset\n",
        "        :param y            : 1D array of the groundtruth labels of the dataset\n",
        "        :param ax          : existing subplot, to draw on it\n",
        "    \"\"\"\n",
        "    # ax.clear()\n",
        "    if X.shape[1] == 2:\n",
        "        # set label of horizontal axis\n",
        "        ax.set_xlabel('f1')\n",
        "        # set label of vertical axis\n",
        "        ax.set_ylabel('f2')\n",
        "        # scatter the points, with red color\n",
        "        ax.scatter(X[:,0], X[:,1], c='black', marker='.', label=title_string)\n",
        "\n",
        "    k = s.shape[0]\n",
        "    color_list = ['r', 'g', 'b', 'c', 'm', 'y']\n",
        "    N_sides = 11\n",
        "\n",
        "    # Iterate over all gaussians\n",
        "    for k_cnt in range(k):\n",
        "\n",
        "        # pick the covariance matrix and mean values of each gaussian\n",
        "        s_k = s[k_cnt]\n",
        "        mu_k = mu[k_cnt]\n",
        "\n",
        "        if s_k.shape[0]==2:\n",
        "            # dataset with 2 features\n",
        "            side_range = np.arange(0, N_sides, 1)\n",
        "            theta = side_range/(N_sides-1)*2*np.pi\n",
        "            matrix = np.array([np.cos(theta), np.sin(theta)])\n",
        "            mu_k = np.expand_dims(mu_k, axis=1)\n",
        "            mu_repeated = np.repeat(mu_k, N_sides, axis=1)\n",
        "            epoints = np.matmul(scipy.linalg.sqrtm(s_k), matrix) + mu_repeated\n",
        "            plt.plot(epoints[0,:], epoints[1,:], color=color_list[k_cnt], linewidth=2)\n",
        "            plt.scatter(mu_k[0], mu_k[1], color=color_list[k_cnt], marker='o', linewidth=2)\n",
        "        elif s_k.shape[0]==3:\n",
        "            # dataset with 3 features\n",
        "            side_range = np.arange(0, N_sides, 1)\n",
        "            theta = side_range/(N_sides-1)*np.pi\n",
        "            phi = side_range/(N_sides-1)*2*np.pi\n",
        "            sin_theta = np.expand_dims(np.sin(theta), axis=1)\n",
        "            cos_theta = np.expand_dims(np.cos(theta), axis=1)\n",
        "            sin_phi = np.expand_dims(np.sin(phi), axis=1)\n",
        "            cos_phi = np.expand_dims(np.cos(phi), axis=1)\n",
        "            sx = np.matmul(sin_theta, cos_phi.transpose())\n",
        "            sy = np.matmul(sin_theta, sin_phi.transpose())\n",
        "            sz = np.matmul(cos_theta, np.ones((1, N_sides)))\n",
        "            svect = np.array([sx.reshape((N_sides*N_sides)), sy.reshape((N_sides*N_sides)), sz.reshape((N_sides*N_sides))])\n",
        "\n",
        "            mu_k = np.expand_dims(mu_k, axis=1)\n",
        "            mu_repeated = np.repeat(mu_k, N_sides*N_sides, axis=1)\n",
        "            epoints = np.matmul(scipy.linalg.sqrtm(s_k), svect) + mu_repeated\n",
        "\n",
        "            ex = epoints[0]\n",
        "            ey = epoints[1]\n",
        "            ez = epoints[2]\n",
        "\n",
        "            ax.plot3D(epoints[0,:], epoints[1,:], epoints[2,:], color=color_list[k_cnt])\n",
        "            ax.plot3D(ex, ey, ez, color=color_list[k_cnt])\n",
        "        else:\n",
        "            print('Each dataset sample should have either 2 or 3 features. Not plotting this one.')\n",
        "    ax.legend()\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())\n",
        "\n",
        "def plot_data_3D(X, title_string, ax):\n",
        "    \"\"\"\n",
        "        :param X            : 2D array of our dataset\n",
        "        :param y            : 1D array of the groundtruth labels of the dataset\n",
        "        :param ax          : existing subplot, to draw on it\n",
        "    \"\"\"\n",
        "    # clear subplot from previous (if any) drawn stuff\n",
        "    ax.clear()\n",
        "    # set label of x axis\n",
        "    ax.set_xlabel('f1')\n",
        "    # set label of y axis\n",
        "    ax.set_ylabel('f2')\n",
        "    # set label of z axis\n",
        "    ax.set_zlabel('f1 + f2')\n",
        "    # scatter the points, with red color\n",
        "    ax.scatter3D(X[:,0], X[:,1], X[:,2], c='black', marker='.', label=title_string)\n",
        "    # add legend to the subplot\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "def save_model(mu, s, p):\n",
        "  GMM_parameters = {}\n",
        "  GMM_parameters['mu'] = mu\n",
        "  GMM_parameters['s'] = s\n",
        "  GMM_parameters['p'] = p\n",
        "  if not os.path.isdir('data/'):\n",
        "    os.mkdir('data/')\n",
        "  npy_filename = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "  np.save(npy_filename, GMM_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9U6wRo8X36_"
      },
      "source": [
        "## Train MoG\n",
        "\n",
        "Read the following blocks of code and understand what it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXZYGJXUW8pk"
      },
      "outputs": [],
      "source": [
        "k = 3\n",
        "# id of the phoneme that will be used (e.g. 1, or 2)\n",
        "p_id = 1\n",
        "X_full = np.zeros((len(f1), 2))\n",
        "X_full[:,0] = f1.copy()\n",
        "X_full[:,1] = f2.copy()\n",
        "X_full = X_full.astype(np.float32)\n",
        "\n",
        "X = X_full[phoneme_id==p_id,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sJtyc3YXVC5"
      },
      "outputs": [],
      "source": [
        "# get number of samples\n",
        "N = X.shape[0]\n",
        "# get dimensionality of our dataset\n",
        "D = X.shape[1]\n",
        "# common practice : GMM weights initially set as 1/k\n",
        "p = np.ones((k))/k\n",
        "# GMM means are picked randomly from data samples\n",
        "random_indices = np.floor(N*np.random.rand((k)))\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "# covariance matrices\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "# number of iterations for the EM algorithm\n",
        "n_iter = 100\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    # initially set to fraction of data covariance\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "# Initialize array Z that will get the predictions of each Gaussian on each sample\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "n_iter = 100\n",
        "for t in range(n_iter):\n",
        "    print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(),Z[:,i]) / np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with diagonal covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "        coef_1 = (X.transpose() - mu_i_repeated)**2\n",
        "        coef_2 = Z[:,i]/np.sum(Z[:,i])\n",
        "        coef_2 = np.expand_dims(coef_2, axis=1)\n",
        "        res_1 = np.squeeze( np.matmul(coef_1, coef_2) )\n",
        "        s[i,:,:] = np.diag(res_1)\n",
        "\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "print('\\nFinished.\\n')\n",
        "print(f\"mean: {mu}, cov: {s}\")\n",
        "save_model(mu, s, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orPA2rOPZg2O"
      },
      "source": [
        "### <font color=\"red\"> Q2. Run the code multiple times for K=3, what do you observe? Use figures and the printed MoG parameters to support your arguments [2 mark] </font>\n",
        "###  Q3. Repeat the training for phoneme_id = 2  and save the parameters [1 mark]\n",
        "### Q4. Repeat training for K=6 for phoneme_id =1 and phoneme_id=2 and save the model parameters [1 mark]\n",
        "\n",
        "Save your MoG model: this should comprise the variables mu, s and p. Include the all the saved model parameters in the submission .zip folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVrJt4Uibldp"
      },
      "outputs": [],
      "source": [
        "### your code here\n",
        "k = 3\n",
        "# id of the phoneme that will be used (e.g. 1, or 2)\n",
        "p_id = 1\n",
        "X_full = np.zeros((len(f1), 2))\n",
        "X_full[:,0] = f1.copy()\n",
        "X_full[:,1] = f2.copy()\n",
        "X_full = X_full.astype(np.float32)\n",
        "\n",
        "X = X_full[phoneme_id==p_id,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get number of samples\n",
        "N = X.shape[0]\n",
        "# get dimensionality of our dataset\n",
        "D = X.shape[1]\n",
        "# common practice : GMM weights initially set as 1/k\n",
        "p = np.ones((k))/k\n",
        "# GMM means are picked randomly from data samples\n",
        "random_indices = np.floor(N*np.random.rand((k)))\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "# covariance matrices\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "# number of iterations for the EM algorithm\n",
        "n_iter = 100\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    # initially set to fraction of data covariance\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "# Initialize array Z that will get the predictions of each Gaussian on each sample\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "n_iter = 100\n",
        "for t in range(n_iter):\n",
        "    print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(),Z[:,i]) / np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with diagonal covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "        coef_1 = (X.transpose() - mu_i_repeated)**2\n",
        "        coef_2 = Z[:,i]/np.sum(Z[:,i])\n",
        "        coef_2 = np.expand_dims(coef_2, axis=1)\n",
        "        res_1 = np.squeeze( np.matmul(coef_1, coef_2) )\n",
        "        s[i,:,:] = np.diag(res_1)\n",
        "\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "print('\\nFinished.\\n')\n",
        "print(f\"mean: {mu}, cov: {s}\")\n",
        "save_model(mu, s, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q4 K=6 P=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### your code here\n",
        "k = 6\n",
        "# id of the phoneme that will be used (e.g. 1, or 2)\n",
        "p_id = 1\n",
        "X_full = np.zeros((len(f1), 2))\n",
        "X_full[:,0] = f1.copy()\n",
        "X_full[:,1] = f2.copy()\n",
        "X_full = X_full.astype(np.float32)\n",
        "\n",
        "X = X_full[phoneme_id==p_id,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get number of samples\n",
        "N = X.shape[0]\n",
        "# get dimensionality of our dataset\n",
        "D = X.shape[1]\n",
        "# common practice : GMM weights initially set as 1/k\n",
        "p = np.ones((k))/k\n",
        "# GMM means are picked randomly from data samples\n",
        "random_indices = np.floor(N*np.random.rand((k)))\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "# covariance matrices\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "# number of iterations for the EM algorithm\n",
        "n_iter = 100\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    # initially set to fraction of data covariance\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "# Initialize array Z that will get the predictions of each Gaussian on each sample\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "n_iter = 100\n",
        "for t in range(n_iter):\n",
        "    print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(),Z[:,i]) / np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with diagonal covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "        coef_1 = (X.transpose() - mu_i_repeated)**2\n",
        "        coef_2 = Z[:,i]/np.sum(Z[:,i])\n",
        "        coef_2 = np.expand_dims(coef_2, axis=1)\n",
        "        res_1 = np.squeeze( np.matmul(coef_1, coef_2) )\n",
        "        s[i,:,:] = np.diag(res_1)\n",
        "\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "print('\\nFinished.\\n')\n",
        "print(f\"mean: {mu}, cov: {s}\")\n",
        "save_model(mu, s, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q4 K=6 P=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### your code here\n",
        "k = 6\n",
        "# id of the phoneme that will be used (e.g. 1, or 2)\n",
        "p_id = 2\n",
        "X_full = np.zeros((len(f1), 2))\n",
        "X_full[:,0] = f1.copy()\n",
        "X_full[:,1] = f2.copy()\n",
        "X_full = X_full.astype(np.float32)\n",
        "\n",
        "X = X_full[phoneme_id==p_id,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get number of samples\n",
        "N = X.shape[0]\n",
        "# get dimensionality of our dataset\n",
        "D = X.shape[1]\n",
        "# common practice : GMM weights initially set as 1/k\n",
        "p = np.ones((k))/k\n",
        "# GMM means are picked randomly from data samples\n",
        "random_indices = np.floor(N*np.random.rand((k)))\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "# covariance matrices\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "# number of iterations for the EM algorithm\n",
        "n_iter = 100\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    # initially set to fraction of data covariance\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "# Initialize array Z that will get the predictions of each Gaussian on each sample\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "n_iter = 100\n",
        "for t in range(n_iter):\n",
        "    print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(),Z[:,i]) / np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with diagonal covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "        coef_1 = (X.transpose() - mu_i_repeated)**2\n",
        "        coef_2 = Z[:,i]/np.sum(Z[:,i])\n",
        "        coef_2 = np.expand_dims(coef_2, axis=1)\n",
        "        res_1 = np.squeeze( np.matmul(coef_1, coef_2) )\n",
        "        s[i,:,:] = np.diag(res_1)\n",
        "\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "print('\\nFinished.\\n')\n",
        "print(f\"mean: {mu}, cov: {s}\")\n",
        "save_model(mu, s, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y84MznI-cC21"
      },
      "source": [
        "### <font color=\"red\"> Q5. Use the 2 MoGs (K=3) learnt in tasks 2 & 3 to build a classifier to discriminate between phonemes 1 and 2, and explain the process in the report [4 marks] </font>\n",
        "\n",
        "Classify using the Maximum Likelihood (ML) criterion and calculate the miss-classification error. Remember that a classification under the ML compares $p(\\mathbf{x};\\boldsymbol\\theta_{1})$, where $\\boldsymbol\\theta_{1}$ are the parameters of the MoG learnt for the first phoneme, with $p(\\mathbf{x};\\boldsymbol\\theta_{2})$, where $\\boldsymbol\\theta_{2}$  are the parameters of the MoG learnt for the second phoneme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoBH4vLDc0Qc"
      },
      "outputs": [],
      "source": [
        "k = 3\n",
        "inds_1 = np.where(phoneme_id==1)\n",
        "inds_2 = np.where(phoneme_id==2)\n",
        "inds_1 = inds_1[0]\n",
        "inds_2 = inds_2[0]\n",
        "inds_1_and_2 = np.concatenate((inds_1, inds_2), axis=0)\n",
        "\n",
        "X = X_full[inds_1_and_2,:]\n",
        "\n",
        "N = X.shape[0]\n",
        "D = X.shape[1]\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 1\n",
        "p_id = 1\n",
        "npy_filename = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename):\n",
        "    GMM_parameters_phoneme_1 = np.load(npy_filename, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_1 = np.ndarray.tolist(GMM_parameters_phoneme_1)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename))\n",
        "mu1 = GMM_parameters_phoneme_1['mu']\n",
        "s1 = GMM_parameters_phoneme_1['s']\n",
        "p1 = GMM_parameters_phoneme_1['p']\n",
        "\n",
        "p_id = 2\n",
        "npy_filename2 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename2):\n",
        "    GMM_parameters_phoneme_2 = np.load(npy_filename2, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_2 = np.ndarray.tolist(GMM_parameters_phoneme_2)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename2))\n",
        "mu2 = GMM_parameters_phoneme_2['mu']\n",
        "s2 = GMM_parameters_phoneme_2['s']\n",
        "p2 = GMM_parameters_phoneme_2['p']\n",
        "\n",
        "\n",
        "# Initialize array Z_phoneme_1 that will get the predictions of each Gaussian on each sample\n",
        "Z_phoneme_1 = np.zeros((N,k)) # shape Nxk\n",
        "Z_phoneme_2 = np.zeros((N,k))\n",
        "# get predictions\n",
        "###your code here\n",
        "Z_phoneme_1 = get_predictions(mu1, s1, p1, X)\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 2\n",
        "p_id = 2\n",
        "###your code here\n",
        "Z_phoneme_2 = get_predictions(mu2, s2, p2, X)\n",
        "\n",
        "# classify each point using Maximum Likelihood\n",
        "total_likelihood_phoneme_1 = np.max(Z_phoneme_1, axis=1)\n",
        "total_likelihood_phoneme_2 = np.max(Z_phoneme_2, axis=1)\n",
        "\n",
        "### your code here\n",
        "classifications = np.where(total_likelihood_phoneme_1 > total_likelihood_phoneme_2, 1, 2)\n",
        "true_labels = phoneme_id[inds_1_and_2]\n",
        "\n",
        "# calculate accuracy\n",
        "### your code here\n",
        "correct_classifications = np.sum(classifications == true_labels)\n",
        "accuracy = correct_classifications / N\n",
        "missclassification_error = 1 - accuracy\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Misclassification Error:', missclassification_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMxM6mgLfXgs"
      },
      "source": [
        "### <font color=\"red\"> Q6. Repeat for K=6 and compare the results in terms of accuracy. [2 mark] </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 6\n",
        "inds_1 = np.where(phoneme_id==1)\n",
        "inds_2 = np.where(phoneme_id==2)\n",
        "inds_1 = inds_1[0]\n",
        "inds_2 = inds_2[0]\n",
        "inds_1_and_2 = np.concatenate((inds_1, inds_2), axis=0)\n",
        "\n",
        "X = X_full[inds_1_and_2,:]\n",
        "\n",
        "N = X.shape[0]\n",
        "D = X.shape[1]\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 1\n",
        "p_id = 1\n",
        "npy_filename1 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename1):\n",
        "    GMM_parameters_phoneme_1 = np.load(npy_filename1, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_1 = np.ndarray.tolist(GMM_parameters_phoneme_1)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename1))\n",
        "mu1 = GMM_parameters_phoneme_1['mu']\n",
        "s1 = GMM_parameters_phoneme_1['s']\n",
        "p1 = GMM_parameters_phoneme_1['p']\n",
        "\n",
        "p_id = 2\n",
        "npy_filename2 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename2):\n",
        "    GMM_parameters_phoneme_2 = np.load(npy_filename2, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_2 = np.ndarray.tolist(GMM_parameters_phoneme_2)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename2))\n",
        "mu2 = GMM_parameters_phoneme_2['mu']\n",
        "s2 = GMM_parameters_phoneme_2['s']\n",
        "p2 = GMM_parameters_phoneme_2['p']\n",
        "\n",
        "\n",
        "\n",
        "# Initialize array Z_phoneme_1 that will get the predictions of each Gaussian on each sample\n",
        "Z_phoneme_1 = np.zeros((N,k)) # shape Nxk\n",
        "Z_phoneme_2 = np.zeros((N,k))\n",
        "# get predictions\n",
        "###your code here\n",
        "Z_phoneme_1 = get_predictions(mu1, s1, p1, X)\n",
        "\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 2\n",
        "p_id = 2\n",
        "###your code here\n",
        "Z_phoneme_2 = get_predictions(mu2, s2, p2, X)\n",
        "\n",
        "# classify each point using Maximum Likelihood\n",
        "### your code here\n",
        "total_likelihood_phoneme_1 = np.max(Z_phoneme_1, axis=1)\n",
        "total_likelihood_phoneme_2 = np.max(Z_phoneme_2, axis=1)\n",
        "\n",
        "\n",
        "# calculate accuracy\n",
        "### your code here\n",
        "\n",
        "classifications = np.where(total_likelihood_phoneme_1 > total_likelihood_phoneme_2, 1, 2)\n",
        "true_labels = phoneme_id[inds_1_and_2]\n",
        "\n",
        "correct_classifications = np.sum(classifications == true_labels)\n",
        "accuracy = correct_classifications / N\n",
        "missclassification_error = 1 - accuracy\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Misclassification Error:', missclassification_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arnPiLFMculy"
      },
      "source": [
        "### <font color=\"red\"> Q7. Display a \"classification matrix\" assigning labels to a grid of all combinations of the F1 and F2 features for the K=3 classifiers from above. Next, repeat this step for K=6 and compare the two. [3 marks] </font>\n",
        "\n",
        "In particular,\n",
        "create a custom uniform grid of points that spans all possible intermediate combinations of $F1$ and $F2$ features, using the features' minimum and maximum values as the limits. (Hint: check documentation for [np.meshgrid](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) and [np.linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) ). Classify each point in the grid using one of your classifiers. That is, create a classification matrix, $\\mathbf{M}$, whose elements are either 0 or 1. $M(i,j)$ is 0 if the point at location $(i,j)$ on the custom grid is classified as belonging to phoneme 1, and is 1 otherwise.\n",
        "\n",
        "### Hint: building the custom grid:\n",
        "Assuming our data were the orange points below, the custom grid would look something like the following (evenly spaced points spanning the minimum to maximum values of both features):\n",
        "\n",
        "![](https://i.imgur.com/khfYx42.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoyGlTdvfsS8"
      },
      "outputs": [],
      "source": [
        "k = 3\n",
        "inds_1 = np.where(phoneme_id==1)\n",
        "inds_2 = np.where(phoneme_id==2)\n",
        "inds_1 = inds_1[0]\n",
        "inds_2 = inds_2[0]\n",
        "inds_1_and_2 = np.concatenate((inds_1, inds_2), axis=0)\n",
        "\n",
        "X = X_full[inds_1_and_2,:]\n",
        "\n",
        "N = X.shape[0]\n",
        "D = X.shape[1]\n",
        "\n",
        "min_f1 = int(np.min(X[:,0]))\n",
        "max_f1 = int(np.max(X[:,0]))\n",
        "min_f2 = int(np.min(X[:,1]))\n",
        "max_f2 = int(np.max(X[:,1]))\n",
        "N_f1 = max_f1 - min_f1\n",
        "N_f2 = max_f2 - min_f2\n",
        "print('f1 range: {}-{} | {} points'.format(min_f1, max_f1, N_f1))\n",
        "print('f2 range: {}-{} | {} points'.format(min_f2, max_f2, N_f2))\n",
        "\n",
        "#########################################\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 1\n",
        "p_id = 1\n",
        "npy_filename1 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename1):\n",
        "    GMM_parameters_phoneme_1 = np.load(npy_filename1, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_1 = np.ndarray.tolist(GMM_parameters_phoneme_1)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename1))\n",
        "mu1 = GMM_parameters_phoneme_1['mu']\n",
        "s1 = GMM_parameters_phoneme_1['s']\n",
        "p1 = GMM_parameters_phoneme_1['p']\n",
        "\n",
        "p_id = 2\n",
        "npy_filename2 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename2):\n",
        "    GMM_parameters_phoneme_2 = np.load(npy_filename2, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_2 = np.ndarray.tolist(GMM_parameters_phoneme_2)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename2))\n",
        "mu2 = GMM_parameters_phoneme_2['mu']\n",
        "s2 = GMM_parameters_phoneme_2['s']\n",
        "p2 = GMM_parameters_phoneme_2['p']\n",
        "\n",
        "\n",
        "f1_vals = np.linspace(min_f1, max_f1, N_f1)\n",
        "f2_vals = np.linspace(min_f2, max_f2, N_f2)\n",
        "\n",
        "f1_grid, f2_grid = np.meshgrid(f1_vals, f2_vals)\n",
        "\n",
        "grid_points = np.c_[f1_grid.ravel(), f2_grid.ravel()]\n",
        "\n",
        "Z_phoneme_1_grid = get_predictions(mu1, s1, p1, grid_points)\n",
        "total_likelihood_phoneme_1_grid = np.max(Z_phoneme_1_grid, axis=1)\n",
        "\n",
        "Z_phoneme_2_grid = get_predictions(mu2, s2, p2, grid_points)\n",
        "total_likelihood_phoneme_2_grid = np.max(Z_phoneme_2_grid, axis=1)\n",
        "\n",
        "classification_results = np.where(total_likelihood_phoneme_1_grid > total_likelihood_phoneme_2_grid, 0.0, 1.0)\n",
        "M = classification_results.reshape(f1_grid.shape)\n",
        "\n",
        "print(\"\\nClassification Matrix:\\n\", M)\n",
        "\n",
        "# Create a custom grid of shape N_f1 x N_f2\n",
        "# The grid will span all the values of (f1, f2) pairs, between [min_f1, max_f1] on f1 axis, and between [min_f2, max_f2] on f2 axis\n",
        "# Then, classify each point [i.e., each (f1, f2) pair] of that grid, to either phoneme 1, or phoneme 2, using the two trained GMMs\n",
        "# Do predictions, using GMM trained on phoneme 1, on custom grid\n",
        "# Do predictions, using GMM trained on phoneme 2, on custom grid\n",
        "# Compare these predictions, to classify each point of the grid\n",
        "# Store these prediction in a 2D numpy array named \"M\", of shape N_f2 x N_f1 (the first dimension is f2 so that we keep f2 in the vertical axis of the plot)\n",
        "# M should contain \"0.0\" in the points that belong to phoneme 1 and \"1.0\" in the points that belong to phoneme 2\n",
        "########################################/\n",
        "\n",
        "################################################\n",
        "# Visualize predictions on custom grid\n",
        "\n",
        "# Create a figure\n",
        "#fig = plt.figure()\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# use aspect='auto' (default is 'equal'), to force the plotted image to be square, when dimensions are unequal\n",
        "plt.imshow(M, aspect='auto')\n",
        "\n",
        "# set label of x axis\n",
        "ax.set_xlabel('f1')\n",
        "# set label of y axis\n",
        "ax.set_ylabel('f2')\n",
        "\n",
        "# set limits of axes\n",
        "plt.xlim((0, N_f1))\n",
        "plt.ylim((0, N_f2))\n",
        "\n",
        "# set range and strings of ticks on axes\n",
        "x_range = np.arange(0, N_f1, step=50)\n",
        "x_strings = [str(x+min_f1) for x in x_range]\n",
        "plt.xticks(x_range, x_strings)\n",
        "y_range = np.arange(0, N_f2, step=200)\n",
        "y_strings = [str(y+min_f2) for y in y_range]\n",
        "plt.yticks(y_range, y_strings)\n",
        "\n",
        "# set title of figure\n",
        "title_string = 'Predictions on custom grid'\n",
        "plt.title(title_string)\n",
        "\n",
        "# add a colorbar\n",
        "plt.colorbar()\n",
        "\n",
        "N_samples = int(X.shape[0]/2)\n",
        "plt.scatter(X[:N_samples, 0] - min_f1, X[:N_samples, 1] - min_f2, marker='.', color='red', label='Phoneme 1')\n",
        "plt.scatter(X[N_samples:, 0] - min_f1, X[N_samples:, 1] - min_f2, marker='.', color='green', label='Phoneme 2')\n",
        "\n",
        "# add legend to the subplot\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 6\n",
        "inds_1 = np.where(phoneme_id==1)\n",
        "inds_2 = np.where(phoneme_id==2)\n",
        "inds_1 = inds_1[0]\n",
        "inds_2 = inds_2[0]\n",
        "inds_1_and_2 = np.concatenate((inds_1, inds_2), axis=0)\n",
        "\n",
        "X = X_full[inds_1_and_2,:]\n",
        "\n",
        "N = X.shape[0]\n",
        "D = X.shape[1]\n",
        "\n",
        "min_f1 = int(np.min(X[:,0]))\n",
        "max_f1 = int(np.max(X[:,0]))\n",
        "min_f2 = int(np.min(X[:,1]))\n",
        "max_f2 = int(np.max(X[:,1]))\n",
        "N_f1 = max_f1 - min_f1\n",
        "N_f2 = max_f2 - min_f2\n",
        "print('f1 range: {}-{} | {} points'.format(min_f1, max_f1, N_f1))\n",
        "print('f2 range: {}-{} | {} points'.format(min_f2, max_f2, N_f2))\n",
        "\n",
        "#########################################\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Get predictions on both phonemes 1 and 2, from a GMM with k components, pretrained on phoneme 1\n",
        "p_id = 1\n",
        "npy_filename1 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename1):\n",
        "    GMM_parameters_phoneme_1 = np.load(npy_filename1, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_1 = np.ndarray.tolist(GMM_parameters_phoneme_1)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename1))\n",
        "mu1 = GMM_parameters_phoneme_1['mu']\n",
        "s1 = GMM_parameters_phoneme_1['s']\n",
        "p1 = GMM_parameters_phoneme_1['p']\n",
        "\n",
        "p_id = 2\n",
        "npy_filename2 = 'data/GMM_params_phoneme_{:02}_k_{:02}.npy'.format(p_id, k)\n",
        "if os.path.isfile(npy_filename2):\n",
        "    GMM_parameters_phoneme_2 = np.load(npy_filename2, allow_pickle=True)\n",
        "    GMM_parameters_phoneme_2 = np.ndarray.tolist(GMM_parameters_phoneme_2)\n",
        "else:\n",
        "    raise('File {} does not exist.'.format(npy_filename2))\n",
        "mu2 = GMM_parameters_phoneme_2['mu']\n",
        "s2 = GMM_parameters_phoneme_2['s']\n",
        "p2 = GMM_parameters_phoneme_2['p']\n",
        "\n",
        "f1_vals = np.linspace(min_f1, max_f1, N_f1)\n",
        "f2_vals = np.linspace(min_f2, max_f2, N_f2)\n",
        "\n",
        "f1_grid, f2_grid = np.meshgrid(f1_vals, f2_vals)\n",
        "\n",
        "grid_points = np.c_[f1_grid.ravel(), f2_grid.ravel()]\n",
        "\n",
        "Z_phoneme_1_grid = get_predictions(mu1, s1, p1, grid_points)\n",
        "total_likelihood_phoneme_1_grid = np.max(Z_phoneme_1_grid, axis=1)\n",
        "\n",
        "Z_phoneme_2_grid = get_predictions(mu2, s2, p2, grid_points)\n",
        "total_likelihood_phoneme_2_grid = np.max(Z_phoneme_2_grid, axis=1)\n",
        "\n",
        "classification_results = np.where(total_likelihood_phoneme_1_grid > total_likelihood_phoneme_2_grid, 0.0, 1.0)\n",
        "M = classification_results.reshape(f1_grid.shape)\n",
        "\n",
        "print(\"\\nClassification Matrix:\\n\", M)\n",
        "\n",
        "# Create a custom grid of shape N_f1 x N_f2\n",
        "# The grid will span all the values of (f1, f2) pairs, between [min_f1, max_f1] on f1 axis, and between [min_f2, max_f2] on f2 axis\n",
        "# Then, classify each point [i.e., each (f1, f2) pair] of that grid, to either phoneme 1, or phoneme 2, using the two trained GMMs\n",
        "# Do predictions, using GMM trained on phoneme 1, on custom grid\n",
        "# Do predictions, using GMM trained on phoneme 2, on custom grid\n",
        "# Compare these predictions, to classify each point of the grid\n",
        "# Store these prediction in a 2D numpy array named \"M\", of shape N_f2 x N_f1 (the first dimension is f2 so that we keep f2 in the vertical axis of the plot)\n",
        "# M should contain \"0.0\" in the points that belong to phoneme 1 and \"1.0\" in the points that belong to phoneme 2\n",
        "########################################/\n",
        "\n",
        "################################################\n",
        "# Visualize predictions on custom grid\n",
        "\n",
        "# Create a figure\n",
        "#fig = plt.figure()\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# use aspect='auto' (default is 'equal'), to force the plotted image to be square, when dimensions are unequal\n",
        "plt.imshow(M, aspect='auto')\n",
        "\n",
        "# set label of x axis\n",
        "ax.set_xlabel('f1')\n",
        "# set label of y axis\n",
        "ax.set_ylabel('f2')\n",
        "\n",
        "# set limits of axes\n",
        "plt.xlim((0, N_f1))\n",
        "plt.ylim((0, N_f2))\n",
        "\n",
        "# set range and strings of ticks on axes\n",
        "x_range = np.arange(0, N_f1, step=50)\n",
        "x_strings = [str(x+min_f1) for x in x_range]\n",
        "plt.xticks(x_range, x_strings)\n",
        "y_range = np.arange(0, N_f2, step=200)\n",
        "y_strings = [str(y+min_f2) for y in y_range]\n",
        "plt.yticks(y_range, y_strings)\n",
        "\n",
        "# set title of figure\n",
        "title_string = 'Predictions on custom grid'\n",
        "plt.title(title_string)\n",
        "\n",
        "# add a colorbar\n",
        "plt.colorbar()\n",
        "\n",
        "N_samples = int(X.shape[0]/2)\n",
        "plt.scatter(X[:N_samples, 0] - min_f1, X[:N_samples, 1] - min_f2, marker='.', color='red', label='Phoneme 1')\n",
        "plt.scatter(X[N_samples:, 0] - min_f1, X[N_samples:, 1] - min_f2, marker='.', color='green', label='Phoneme 2')\n",
        "\n",
        "# add legend to the subplot\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UraAKMXuhiwR"
      },
      "source": [
        "Create a new dataset that will contain 3 columns, as follows:\n",
        "\\begin{equation}\n",
        "    X = [F1, F2, F1+F2]\n",
        "\\end{equation}\n",
        "\n",
        "### <font color=\"red\"> Q8. Try to fit a MoG model to the new data. What is the problem that you observe? Explain why it occurs [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7q1EEkJhwmu"
      },
      "outputs": [],
      "source": [
        "p_id = 1 # id of the phoneme that will be used (e.g. 1, or 2)\n",
        "\n",
        "k = 3 # number of GMM components\n",
        "X = np.zeros((len(f1), 3))\n",
        "#########################################\n",
        "# Write your code here\n",
        "# The shape of X is be two-dimensional. Each row will represent a sample of the dataset, and each column will represent a feature (e.g. f1 or f2 or f1+f2)\n",
        "# Store f1 in the first column of X, f2 in the second column of X and f1+f2 in the third column of X\n",
        "# Filter X to, contain only samples that belong to the chosen phoneme.\n",
        "X[:, 0] = f1  # F1 feature\n",
        "X[:, 1] = f2  # F2 feature\n",
        "X[:, 2] = f1+f2 # F1+F2 combined feature\n",
        "\n",
        "X = X[phoneme_id == p_id]\n",
        "\n",
        "print(X)\n",
        "\n",
        "#########################################\n",
        "fig = plt.figure()\n",
        "ax1 = plt.axes(projection='3d')\n",
        "title_string = 'Phoneme {}'.format(p_id)\n",
        "plot_data_3D(X=X, title_string=title_string, ax=ax1)\n",
        "\n",
        "N, D = X.shape\n",
        "p = np.ones((k))/k\n",
        "random_indices = np.floor(N*np.random.rand(k))\n",
        "\n",
        "# print(f\"Random indices: {random_indices}\")\n",
        "\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "n_iter = 150\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "for t in range(n_iter):\n",
        "    print('****************************************')\n",
        "    print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "\n",
        "    # Z.astype(np.float32)\n",
        "    print(f\"Z: {Z}\")\n",
        "\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(), Z[:,i])/np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with full covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\n",
        "        term_1 = X.transpose() - mu_i_repeated\n",
        "        term_2 = np.repeat(np.expand_dims(Z[:,i], axis=1), D, axis=1) * term_1.transpose()\n",
        "        s[i,:,:] = np.matmul(term_1, term_2)/np.sum(Z[:,i])\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RcoOpPgiKM2"
      },
      "source": [
        "### <font color=\"red\"> Q9. Suggest ways of overcoming the singularity problem and implement one of them. Show any training outputs in the report and discuss. [3 marks] </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K=3 Phoneme_id=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_id = 1 # id of the phoneme that will be used (e.g. 1, or 2)\n",
        "\n",
        "k = 3 # number of GMM components\n",
        "X = np.zeros((len(f1), 3))\n",
        "#########################################\n",
        "# Write your code here\n",
        "# The shape of X is be two-dimensional. Each row will represent a sample of the dataset, and each column will represent a feature (e.g. f1 or f2 or f1+f2)\n",
        "# Store f1 in the first column of X, f2 in the second column of X and f1+f2 in the third column of X\n",
        "# Filter X to, contain only samples that belong to the chosen phoneme.\n",
        "X[:, 0] = f1  # F1 feature\n",
        "X[:, 1] = f2  # F2 feature\n",
        "# X[:, 2] = np.sqrt(f1 + f2)\n",
        "# X[:, 2] = f1+f2\n",
        "\n",
        "# normalizing f1+f2\n",
        "x=f1+f2\n",
        "m = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "X[:, 2] = (x - m)/std\n",
        "\n",
        "X = X[phoneme_id == p_id]\n",
        "\n",
        "#########################################\n",
        "fig = plt.figure()\n",
        "ax1 = plt.axes(projection='3d')\n",
        "title_string = 'Phoneme {}'.format(p_id)\n",
        "plot_data_3D(X=X, title_string=title_string, ax=ax1)\n",
        "\n",
        "N, D = X.shape\n",
        "p = np.ones((k))/k\n",
        "random_indices = np.floor(N*np.random.rand(k))\n",
        "\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "n_iter = 150\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "for t in range(n_iter):\n",
        "    # print('****************************************')\n",
        "    # print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "\n",
        "    # Z.astype(np.float32)\n",
        "    # print(f\"Z: {Z}\")\n",
        "\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(), Z[:,i])/np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with full covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\n",
        "        term_1 = X.transpose() - mu_i_repeated\n",
        "        term_2 = np.repeat(np.expand_dims(Z[:,i], axis=1), D, axis=1) * term_1.transpose()\n",
        "        s[i,:,:] = np.matmul(term_1, term_2)/np.sum(Z[:,i])\n",
        "        # s[i,:,:] += 0.001 * np.eye(D)\n",
        "        # s[i, :, :] = np.identity(D) * np.diag(s[i])\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K=3 Phoneme_id=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_id = 2 # id of the phoneme that will be used (e.g. 1, or 2)\n",
        "\n",
        "k = 3 # number of GMM components\n",
        "X = np.zeros((len(f1), 3))\n",
        "#########################################\n",
        "# Write your code here\n",
        "# The shape of X is be two-dimensional. Each row will represent a sample of the dataset, and each column will represent a feature (e.g. f1 or f2 or f1+f2)\n",
        "# Store f1 in the first column of X, f2 in the second column of X and f1+f2 in the third column of X\n",
        "# Filter X to, contain only samples that belong to the chosen phoneme.\n",
        "X[:, 0] = f1  # F1 feature\n",
        "X[:, 1] = f2  # F2 feature\n",
        "X[:, 2] = np.sqrt(f1 + f2)\n",
        "# X[:, 2] = f1+f2\n",
        "\n",
        "# x=f1+f2\n",
        "# m = np.mean(x, axis=0)\n",
        "# std = np.std(x, axis=0)\n",
        "# X[:, 2] = (x - m)/std\n",
        "\n",
        "# f1+f2\n",
        "\n",
        "X = X[phoneme_id == p_id]\n",
        "\n",
        "#########################################\n",
        "fig = plt.figure()\n",
        "ax1 = plt.axes(projection='3d')\n",
        "title_string = 'Phoneme {}'.format(p_id)\n",
        "plot_data_3D(X=X, title_string=title_string, ax=ax1)\n",
        "\n",
        "N, D = X.shape\n",
        "p = np.ones((k))/k\n",
        "random_indices = np.floor(N*np.random.rand(k))\n",
        "\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "n_iter = 150\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "for t in range(n_iter):\n",
        "    # print('****************************************')\n",
        "    # print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "\n",
        "    # Z.astype(np.float32)\n",
        "    # print(f\"Z: {Z}\")\n",
        "\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(), Z[:,i])/np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with full covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\n",
        "        term_1 = X.transpose() - mu_i_repeated\n",
        "        term_2 = np.repeat(np.expand_dims(Z[:,i], axis=1), D, axis=1) * term_1.transpose()\n",
        "        s[i,:,:] = np.matmul(term_1, term_2)/np.sum(Z[:,i])\n",
        "        s[i,:,:] += 0.001 * np.eye(D) # adding regularizzation term\n",
        "        # s[i, :, :] = np.identity(D) * np.diag(s[i])\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K=6 Phoneme_id=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_id = 1 # id of the phoneme that will be used (e.g. 1, or 2)\n",
        "\n",
        "k = 6 # number of GMM components\n",
        "X = np.zeros((len(f1), 3))\n",
        "#########################################\n",
        "# Write your code here\n",
        "# The shape of X is be two-dimensional. Each row will represent a sample of the dataset, and each column will represent a feature (e.g. f1 or f2 or f1+f2)\n",
        "# Store f1 in the first column of X, f2 in the second column of X and f1+f2 in the third column of X\n",
        "# Filter X to, contain only samples that belong to the chosen phoneme.\n",
        "X[:, 0] = f1  # F1 feature\n",
        "X[:, 1] = f2  # F2 feature\n",
        "# X[:, 2] = np.sqrt(f1 + f2)\n",
        "# X[:, 2] = f1+f2\n",
        "\n",
        "x=f1+f2\n",
        "m = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "X[:, 2] = (x - m)/std\n",
        "\n",
        "# f1+f2\n",
        "\n",
        "X = X[phoneme_id == p_id]\n",
        "\n",
        "#########################################\n",
        "fig = plt.figure()\n",
        "ax1 = plt.axes(projection='3d')\n",
        "title_string = 'Phoneme {}'.format(p_id)\n",
        "plot_data_3D(X=X, title_string=title_string, ax=ax1)\n",
        "\n",
        "N, D = X.shape\n",
        "p = np.ones((k))/k\n",
        "random_indices = np.floor(N*np.random.rand(k))\n",
        "\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "n_iter = 150\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "for t in range(n_iter):\n",
        "    # print('****************************************')\n",
        "    # print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "\n",
        "    # Z.astype(np.float32)\n",
        "    # print(f\"Z: {Z}\")\n",
        "\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(), Z[:,i])/np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with full covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\n",
        "        term_1 = X.transpose() - mu_i_repeated\n",
        "        term_2 = np.repeat(np.expand_dims(Z[:,i], axis=1), D, axis=1) * term_1.transpose()\n",
        "        s[i,:,:] = np.matmul(term_1, term_2)/np.sum(Z[:,i])\n",
        "        s[i,:,:] += 0.001 * np.eye(D)\n",
        "        # s[i, :, :] = np.identity(D) * np.diag(s[i])\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K=6 Phoneme_id=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_id = 2 # id of the phoneme that will be used (e.g. 1, or 2)\n",
        "\n",
        "k = 6 # number of GMM components\n",
        "X = np.zeros((len(f1), 3))\n",
        "#########################################\n",
        "# Write your code here\n",
        "# The shape of X is be two-dimensional. Each row will represent a sample of the dataset, and each column will represent a feature (e.g. f1 or f2 or f1+f2)\n",
        "# Store f1 in the first column of X, f2 in the second column of X and f1+f2 in the third column of X\n",
        "# Filter X to, contain only samples that belong to the chosen phoneme.\n",
        "X[:, 0] = f1  # F1 feature\n",
        "X[:, 1] = f2  # F2 feature\n",
        "# X[:, 2] = np.sqrt(f1 + f2)\n",
        "# X[:, 2] = f1+f2\n",
        "\n",
        "x=f1+f2\n",
        "m = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "X[:, 2] = (x - m)/std\n",
        "\n",
        "# f1+f2\n",
        "\n",
        "X = X[phoneme_id == p_id]\n",
        "\n",
        "#########################################\n",
        "fig = plt.figure()\n",
        "ax1 = plt.axes(projection='3d')\n",
        "title_string = 'Phoneme {}'.format(p_id)\n",
        "plot_data_3D(X=X, title_string=title_string, ax=ax1)\n",
        "\n",
        "N, D = X.shape\n",
        "p = np.ones((k))/k\n",
        "random_indices = np.floor(N*np.random.rand(k))\n",
        "\n",
        "random_indices = random_indices.astype(int)\n",
        "mu = X[random_indices,:] # shape kxD\n",
        "s = np.zeros((k,D,D)) # shape kxDxD\n",
        "n_iter = 150\n",
        "\n",
        "# initialize covariances\n",
        "for i in range(k):\n",
        "    cov_matrix = np.cov(X.transpose())\n",
        "    s[i,:,:] = cov_matrix/k\n",
        "\n",
        "Z = np.zeros((N,k)) # shape Nxk\n",
        "\n",
        "###############################\n",
        "# run Expectation Maximization algorithm for n_iter iterations\n",
        "for t in range(n_iter):\n",
        "    # print('****************************************')\n",
        "    # print('Iteration {:03}/{:03}'.format(t+1, n_iter))\n",
        "\n",
        "    # Do the E-step\n",
        "    Z = get_predictions(mu, s, p, X)\n",
        "\n",
        "    # Z.astype(np.float32)\n",
        "    # print(f\"Z: {Z}\")\n",
        "\n",
        "    Z = normalize(Z, axis=1, norm='l1')\n",
        "    # Do the M-step:\n",
        "    for i in range(k):\n",
        "        mu[i,:] = np.matmul(X.transpose(), Z[:,i])/np.sum(Z[:,i])\n",
        "\n",
        "        ###################################################\n",
        "        # We will fit Gaussians with full covariance matrices:\n",
        "        mu_i = mu[i,:]\n",
        "        mu_i = np.expand_dims(mu_i, axis=1)\n",
        "        mu_i_repeated = np.repeat(mu_i, N, axis=1)\n",
        "\n",
        "        term_1 = X.transpose() - mu_i_repeated\n",
        "        term_2 = np.repeat(np.expand_dims(Z[:,i], axis=1), D, axis=1) * term_1.transpose()\n",
        "        s[i,:,:] = np.matmul(term_1, term_2)/np.sum(Z[:,i])\n",
        "        s[i,:,:] += 0.001 * np.eye(D)\n",
        "        p[i] = np.mean(Z[:,i])\n",
        "\n",
        "plot_gaussians(ax1, 2*s, mu, X, 'Phoneme {}'.format(p_id))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2PebY0ALYbI7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
